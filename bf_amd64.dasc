|.arch x64
|.actionlist actions
|.section code

// AMD64-specific wrapper functions
static int putchar_wrapper(int c) {
    return putchar(c);
}

static int getchar_wrapper(void) {
    return getchar();
}

// AMD64-specific compilation function
static void compile_bf_arch(dasm_State **Dst, char instruction) {
    switch (instruction) {
        case '>':
            |  add qword [rsp+8], 1    // Increment memory pointer on stack
            break;
        case '<':
            |  sub qword [rsp+8], 1    // Decrement memory pointer on stack
            break;
        case '+':
            |  mov rax, [rsp+8]      // Load memory pointer from stack
            |  inc byte [rax]        // Increment value at memory pointer
            break;
        case '-':
            |  mov rax, [rsp+8]      // Load memory pointer from stack
            |  dec byte [rax]        // Decrement value at memory pointer
            break;
        case '.':
            |  mov rax, [rsp+8]      // Load memory pointer from stack
            |  movzx edi, byte [rax] // Load byte and put in first argument register
            |  mov64 rax, (uintptr_t)putchar_wrapper  // Load function pointer into rax
            |  call rax              // Call through register
            break;
        case ',':
            |  mov64 rax, (uintptr_t)getchar_wrapper   // Load function pointer
            |  call rax              // Call through register
            |  mov rdx, [rsp+8]      // Load memory pointer from stack
            |  mov [rdx], al         // Store result at memory pointer
            break;
    }
}

// AMD64-specific optimized compilation function with run-length encoding
static void compile_bf_arch_optimized(dasm_State **Dst, char instruction, int count) {
    switch (instruction) {
        case '>':
            if (count == 1) {
                |  add qword [rsp+8], 1
            } else {
                |  add qword [rsp+8], count
            }
            break;
        case '<':
            if (count == 1) {
                |  sub qword [rsp+8], 1
            } else {
                |  sub qword [rsp+8], count
            }
            break;
        case '+':
            if (count == 1) {
                |  mov rax, [rsp+8]
                |  inc byte [rax]
            } else if (count <= 127) {
                |  mov rax, [rsp+8]
                |  add byte [rax], count
            } else {
                |  mov rax, [rsp+8]
                |  add byte [rax], count  // x86 allows larger immediates
            }
            break;
        case '-':
            if (count == 1) {
                |  mov rax, [rsp+8]
                |  dec byte [rax]
            } else if (count <= 127) {
                |  mov rax, [rsp+8]
                |  sub byte [rax], count
            } else {
                |  mov rax, [rsp+8]
                |  sub byte [rax], count  // x86 allows larger immediates
            }
            break;
    }
}


// AMD64-specific copy cell optimization (copy only, no clearing)
static void compile_bf_copy_cell(dasm_State **Dst, int offset) {
    |  mov rax, [rsp+8]              // Load memory pointer
    |  mov dl, [rax]                 // Load from source cell
    if (offset >= -128 && offset <= 127) {
        |  add [rax+offset], dl      // Add to destination cell at offset
    } else {
        |  add rax, offset           // Add offset to pointer
        |  add [rax], dl             // Add to destination cell
    }
    // Note: Source cell clearing is now handled by explicit SET_CONST(0)
}

// AMD64-specific multiplication optimization for n*m patterns
static void compile_bf_mul_const(dasm_State **Dst, int multiplier, int target_offset) {
    // Multiply current cell by multiplier, add to target cell
    // Semantics: target += source * multiplier; source = 0
    |  mov rax, [rsp+8]              // Load memory pointer
    |  movzx ecx, byte [rax]         // Load source value (zero-extend to 32-bit)
    |  imul ecx, multiplier          // Multiply by constant
    if (target_offset == 1) {
        |  add [rax+1], cl           // Add to target (common case)
    } else if (target_offset <= 127) {
        |  add [rax+target_offset], cl  // Add to target
    } else {
        |  add rax, target_offset    // Large offset
        |  add [rax], cl             // Add to target
    }
    |  mov rax, [rsp+8]              // Reload memory pointer
    |  mov byte [rax], 0             // Clear source cell
}

static void compile_bf_prologue(dasm_State **Dst) {
    |  push rbp
    |  mov rbp, rsp
    |  push rdi         // Save memory pointer
    |  sub rsp, 8       // Align stack for function calls (16-byte alignment)
}

static void compile_bf_epilogue(dasm_State **Dst) {
    |  xor eax, eax
    |  add rsp, 16      // Remove alignment padding and memory pointer
    |  pop rbp
    |  ret
}

static void compile_bf_loop_start(dasm_State **Dst, int loop_end) {
    |  mov rax, [rsp+8]      // Load memory pointer from stack
    |  cmp byte [rax], 0     // Compare value at memory pointer
    |  je =>(loop_end)
}

static void compile_bf_loop_end(dasm_State **Dst, int back_to_start) {
    |  mov rax, [rsp+8]      // Load memory pointer from stack
    |  cmp byte [rax], 0     // Compare value at memory pointer
    |  jne =>(back_to_start)
}

static void compile_bf_label(dasm_State **Dst, int label) {
    |=>(label):
}

// AST-based compilation wrapper functions
static void compile_bf_move_ptr(dasm_State **Dst, int count) {
    if (count > 0) {
        compile_bf_arch_optimized(Dst, '>', count);
    } else if (count < 0) {
        compile_bf_arch_optimized(Dst, '<', -count);
    }
}

static void compile_bf_add_val(dasm_State **Dst, int count, int offset) {
    if (offset == 0) {
        // Normal ADD at current position
        if (count > 0) {
            compile_bf_arch_optimized(Dst, '+', count);
        } else if (count < 0) {
            compile_bf_arch_optimized(Dst, '-', -count);
        }
    } else {
        // ADD at offset
        |  mov rax, [rsp+8]              // Load memory pointer
        if (count > 0) {
            if (count == 1 && offset >= -128 && offset <= 127) {
                |  inc byte [rax+offset]     // Increment at offset
            } else if (count <= 127 && offset >= -128 && offset <= 127) {
                |  add byte [rax+offset], count  // Add value at offset
            } else {
                |  add rax, offset           // Add offset to pointer
                |  add byte [rax], count     // Add value at adjusted pointer
            }
        } else if (count < 0) {
            if (count == -1 && offset >= -128 && offset <= 127) {
                |  dec byte [rax+offset]     // Decrement at offset
            } else if (count >= -127 && offset >= -128 && offset <= 127) {
                |  sub byte [rax+offset], -count  // Subtract value at offset
            } else {
                |  add rax, offset           // Add offset to pointer
                |  sub byte [rax], -count    // Subtract value at adjusted pointer
            }
        }
    }
}

static void compile_bf_input(dasm_State **Dst, int offset) {
    if (offset == 0) {
        compile_bf_arch(Dst, ',');
    } else {
        |  mov64 rax, (uintptr_t)getchar_wrapper   // Load function pointer
        |  call rax                               // Call through register
        |  mov rdx, [rsp+8]                       // Load memory pointer from stack
        if (offset >= -128 && offset <= 127) {
            |  mov [rdx+offset], al               // Store result at offset
        } else {
            |  add rdx, offset                    // Add offset to pointer
            |  mov [rdx], al                      // Store result at adjusted pointer
        }
    }
}

static void compile_bf_output(dasm_State **Dst, int offset) {
    if (offset == 0) {
        compile_bf_arch(Dst, '.');
    } else {
        |  mov rax, [rsp+8]                       // Load memory pointer from stack
        if (offset >= -128 && offset <= 127) {
            |  movzx edi, byte [rax+offset]       // Load byte from offset and put in first argument register
        } else {
            |  add rax, offset                    // Add offset to pointer
            |  movzx edi, byte [rax]              // Load byte and put in first argument register
        }
        |  mov64 rax, (uintptr_t)putchar_wrapper  // Load function pointer into rax
        |  call rax                               // Call through register
    }
}

// AMD64-specific set constant optimization
static void compile_bf_set_const(dasm_State **Dst, int value) {
    |  mov rax, [rsp+8]              // Load memory pointer
    if (value == 0) {
        |  mov byte [rax], 0          // Set to zero
    } else if (value > 0 && value <= 255) {
        |  mov byte [rax], value      // Set positive value
    } else {
        |  mov byte [rax], (value & 0xFF)  // Set value (truncate to byte)
    }
}

