|.arch arm64
|.actionlist actions
|.section code

// ARM64-specific wrapper functions
static int putchar_wrapper(int c) {
    return putchar(c);
}

static int getchar_wrapper(void) {
    return getchar();
}

// ARM64-specific compilation function
static void compile_bf_arch(dasm_State **Dst, char instruction) {
    switch (instruction) {
        case '>':
            |  add x19, x19, #1
            break;
        case '<':
            |  sub x19, x19, #1
            break;
        case '+':
            |  ldrb w0, [x19]
            |  add w0, w0, #1
            |  strb w0, [x19]
            break;
        case '-':
            |  ldrb w0, [x19]
            |  sub w0, w0, #1
            |  strb w0, [x19]
            break;
        case '.':
            |  ldrb w0, [x19]
            |  sxtb w0, w0
            |  mov x16, #(uintptr_t)putchar_wrapper & 0xffff
            |  movk x16, #((uintptr_t)putchar_wrapper >> 16) & 0xffff, lsl #16
            |  movk x16, #((uintptr_t)putchar_wrapper >> 32) & 0xffff, lsl #32
            |  movk x16, #((uintptr_t)putchar_wrapper >> 48) & 0xffff, lsl #48
            |  blr x16
            break;
        case ',':
            |  mov x16, #(uintptr_t)getchar_wrapper & 0xffff
            |  movk x16, #((uintptr_t)getchar_wrapper >> 16) & 0xffff, lsl #16
            |  movk x16, #((uintptr_t)getchar_wrapper >> 32) & 0xffff, lsl #32
            |  movk x16, #((uintptr_t)getchar_wrapper >> 48) & 0xffff, lsl #48
            |  blr x16
            |  strb w0, [x19]
            break;
    }
}

// ARM64-specific optimized compilation function with run-length encoding
static void compile_bf_arch_optimized(dasm_State **Dst, char instruction, int count) {
    switch (instruction) {
        case '>':
            if (count == 1) {
                |  add x19, x19, #1
            } else if (count <= 4095) {
                |  add x19, x19, #count
            } else {
                // Handle large counts that don't fit in immediate
                |  mov x16, #count
                |  add x19, x19, x16
            }
            break;
        case '<':
            if (count == 1) {
                |  sub x19, x19, #1
            } else if (count <= 4095) {
                |  sub x19, x19, #count
            } else {
                // Handle large counts that don't fit in immediate
                |  mov x16, #count
                |  sub x19, x19, x16
            }
            break;
        case '+':
            if (count == 1) {
                |  ldrb w0, [x19]
                |  add w0, w0, #1
                |  strb w0, [x19]
            } else if (count <= 255) {
                |  ldrb w0, [x19]
                |  add w0, w0, #count
                |  strb w0, [x19]
            } else {
                // Handle large counts or overflow
                |  ldrb w0, [x19]
                |  mov w16, #count
                |  add w0, w0, w16
                |  strb w0, [x19]
            }
            break;
        case '-':
            if (count == 1) {
                |  ldrb w0, [x19]
                |  sub w0, w0, #1
                |  strb w0, [x19]
            } else if (count <= 255) {
                |  ldrb w0, [x19]
                |  sub w0, w0, #count
                |  strb w0, [x19]
            } else {
                // Handle large counts or overflow
                |  ldrb w0, [x19]
                |  mov w16, #count
                |  sub w0, w0, w16
                |  strb w0, [x19]
            }
            break;
    }
}


// ARM64-specific copy cell optimization (copy only, no clearing)
static void compile_bf_copy_cell(dasm_State **Dst, int offset) {
    |  ldrb w0, [x19]                    // Load from source cell
    if (offset >= -256 && offset <= 255) {
        |  ldrb w1, [x19, #offset]       // Load current destination value
        |  add w0, w0, w1                // Add source to destination
        |  strb w0, [x19, #offset]       // Store to destination cell at offset
    } else {
        |  add x19, x19, #offset         // Add offset to pointer
        |  ldrb w1, [x19]                // Load current destination value
        |  add w0, w0, w1                // Add source to destination
        |  strb w0, [x19]                // Store to destination cell
        |  sub x19, x19, #offset         // Restore pointer
    }
    // Note: Source cell clearing is now handled by explicit SET_CONST(0)
}

// ARM64-specific multiplication optimization for n*m patterns
static void compile_bf_mul_const(dasm_State **Dst, int multiplier, int target_offset) {
    // Multiply current cell by multiplier, add to target cell
    // Semantics: target += source * multiplier; source = 0
    |  ldrb w0, [x19]                    // Load source value
    |  mov w1, #multiplier               // Load multiplier  
    |  mul w0, w0, w1                    // source * multiplier
    if (target_offset == 1) {
        |  ldrb w1, [x19, #1]            // Load current target value
        |  add w0, w0, w1                // Add to existing target value
        |  strb w0, [x19, #1]            // Store to target (common case)
    } else if (target_offset <= 255) {
        |  ldrb w1, [x19, #target_offset] // Load current target value
        |  add w0, w0, w1                // Add to existing target value
        |  strb w0, [x19, #target_offset] // Store to target
    } else {
        |  mov x16, #target_offset       // Large offset
        |  ldrb w1, [x19, x16]           // Load current target value
        |  add w0, w0, w1                // Add to existing target value
        |  strb w0, [x19, x16]           // Store to target
    }
    |  mov w0, #0                        // Clear temp
    |  strb w0, [x19]                    // Clear source cell
}

static void compile_bf_prologue(dasm_State **Dst) {
    |  stp x29, x30, [sp, #-32]!
    |  mov x29, sp
    |  str x19, [sp, #16]
    |  mov x19, x0
}

static void compile_bf_epilogue(dasm_State **Dst) {
    |  mov w0, #0
    |  ldr x19, [sp, #16]
    |  ldp x29, x30, [sp], #32
    |  ret
}

static void compile_bf_loop_start(dasm_State **Dst, int loop_end) {
    |  ldrb w0, [x19]
    |  cbz w0, =>(loop_end)
}

static void compile_bf_loop_end(dasm_State **Dst, int back_to_start) {
    |  ldrb w0, [x19]
    |  cbnz w0, =>(back_to_start)
}

static void compile_bf_label(dasm_State **Dst, int label) {
    |=>(label):
}

// AST-based compilation wrapper functions
static void compile_bf_move_ptr(dasm_State **Dst, int count) {
    if (count > 0) {
        compile_bf_arch_optimized(Dst, '>', count);
    } else if (count < 0) {
        compile_bf_arch_optimized(Dst, '<', -count);
    }
}

static void compile_bf_add_val(dasm_State **Dst, int count, int offset) {
    if (offset == 0) {
        // Normal ADD at current position
        if (count > 0) {
            compile_bf_arch_optimized(Dst, '+', count);
        } else if (count < 0) {
            compile_bf_arch_optimized(Dst, '-', -count);
        }
    } else {
        // ADD at offset
        if (count > 0) {
            if (count == 1 && offset >= -256 && offset <= 255) {
                |  ldrb w0, [x19, #offset]       // Load from offset
                |  add w0, w0, #1                // Increment
                |  strb w0, [x19, #offset]       // Store back at offset
            } else if (count <= 255 && offset >= -256 && offset <= 255) {
                |  ldrb w0, [x19, #offset]       // Load from offset
                |  add w0, w0, #count            // Add value
                |  strb w0, [x19, #offset]       // Store back at offset
            } else {
                |  add x19, x19, #offset         // Add offset to pointer
                |  ldrb w0, [x19]                // Load from adjusted pointer
                |  add w0, w0, #count            // Add value
                |  strb w0, [x19]                // Store back
                |  sub x19, x19, #offset         // Restore pointer
            }
        } else if (count < 0) {
            if (count == -1 && offset >= -256 && offset <= 255) {
                |  ldrb w0, [x19, #offset]       // Load from offset
                |  sub w0, w0, #1                // Decrement
                |  strb w0, [x19, #offset]       // Store back at offset
            } else if (count >= -255 && offset >= -256 && offset <= 255) {
                |  ldrb w0, [x19, #offset]       // Load from offset
                |  sub w0, w0, #(-count)         // Subtract value
                |  strb w0, [x19, #offset]       // Store back at offset
            } else {
                |  add x19, x19, #offset         // Add offset to pointer
                |  ldrb w0, [x19]                // Load from adjusted pointer
                |  sub w0, w0, #(-count)         // Subtract value
                |  strb w0, [x19]                // Store back
                |  sub x19, x19, #offset         // Restore pointer
            }
        }
    }
}

static void compile_bf_input(dasm_State **Dst) {
    compile_bf_arch(Dst, ',');
}

// ARM64-specific set constant optimization
static void compile_bf_set_const(dasm_State **Dst, int value) {
    if (value == 0) {
        |  mov w0, #0                     // Load zero
        |  strb w0, [x19]                 // Set to zero
    } else if (value > 0 && value <= 255) {
        |  mov w0, #value                 // Load positive value
        |  strb w0, [x19]                 // Set value
    } else {
        |  mov w0, #(value & 0xFF)        // Load value (truncate to byte)
        |  strb w0, [x19]                 // Set value
    }
}

